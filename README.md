# Multilingual-Sign-Language-to-Speech-System-using-YOLO-LG
This project aims to extend the YOLO-LG model to recognize sign language gestures in real-time and convert them into speech in multiple languages. It is designed to bridge communication gaps for hearing-impaired individuals by enabling smooth interaction with people who do not know sign language.
